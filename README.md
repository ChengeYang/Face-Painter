# Face Painter
-----------------------------------------------------------------------------------------
#### ME-495 Final Project, Fall 2018, Northwestern University
#### Group members: Mark Dyehouse, Veronica Medrano, Huan Weng, Chenge Yang, Guo Ye

<a href="http://www.youtube.com/watch?feature=player_embedded&v=AccB97JPMUE
" target="_blank"><img src="http://img.youtube.com/vi/AccB97JPMUE/0.jpg" 
alt="IMAGE ALT TEXT HERE" width="640" height="480" border="10" /></a>

-----------------------------------------------------------------------------------------
## Introduction
Using ROS, image processing, motion-planning, and trajectory solving, we built a system which takes an image with camera and transforms it into trajectories which allow the Sawyer robot to draw it on a surface after calibration and localization are performed.

### Objective
This goal of this project is to take a photo of a person and draw his face with a marker using Sawyer robot.

### Perception
* The initial image is taken from a USB camera. Then, we apply the Haar Cascade Classifiers in OpenCV to detect and crop the face image. After resizing the face image, the Canny edge detector is used to extract the edgemap of the face which is then passed to trajectory planning. The image is transformed with CV Bridge between ROS and OpenCV.

* The location of the drawing surface is detected using AR tags with the hand camera of Sawyer. Through localizing the AR tags at the four corners, the position, orientation and size of the white board are determined.

* Due to the bad quality of the Sawyer hand camera, the AR tags cannot be accurately localized from a long distance. Thus, the robot hand has to move closely to each of the four AR tags and record the positions separately.

* The coordinates of the Sawyer tf tree and AR tags, as well as the image of the Sawyer hand camera are visualized in rviz.

### Trajectory Planning
* We apply a Depth-First Search together with eage following algorithm to transfer a edgemap into a series of Cartesian points. Using DFS enables us to achieve consistent line-following while simultaneously minimizing the number of times we need to lift the end-effector.

* The break points between each edge segment are represented by (-1,-1)

### Robot Control
* IK solver: We use the function "IKinSpace" in "modern_robotics" library to solve any inverse kinematics during drawing step. The Jacobian matrix and home configuration are derived from the specification of the Sawyer robot. (http://mfg.rethinkrobotics.com/intera/Sawyer_Hardware)

*  The first point's initial guess is choosed to be close to the AR tag at left-top corner of the drawing board. Then, the joint angles of the last point are taken as the initial guess for the follwing trajectory points. Taking the advantage of the trajectory generated by Deep First Search (DFS), every point in the trajectory is close to the last point and the next point.

* Weâ€™re using JTAS control mode: position_w_id, by which we can send the velocity and acceleration between two waypoints to JTAS. 

-----------------------------------------------------------------------------------------
## Implementation

### Launch file
* 

### Noes
* [control.py][./scripts/control.py]: Launch

### Topics
* 

### Messages
* 

### 

### External Packages
* [OpenCV](https://opencv.org/)

* [ar_track_alvar](http://wiki.ros.org/ar_track_alvar)
